{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0881a29f-8bfa-45d7-b204-239ddbf8150f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikipedia page token count: 633\n",
      "Question: Based on the text, provide a short cohesive description (100 words) of the countries the composer had affiliations with or citizenships in\n",
      "Answer: Ivan Ivanovich Dzerzhinsky was affiliated with and held citizenship in the Soviet Union and Russia. Born in Tambov, he studied music in Moscow and later spent time at institutions in Leningrad (now St. Petersburg) and the wider Russian territory. His works were recognized by official entities within the Soviet regime, which underscores his significant affiliation with this country. Despite the eventual decline of his musical influence, his early successes and administrative roles highlight his strong ties to the Soviet and Russian cultural landscape.\n",
      "\n",
      "\n",
      "Wikipedia page token count: 633\n",
      "Question: Based on the previous description, please provide a short (1-3 words) nationality of the composer\n",
      "Answer: Russian\n",
      "\n",
      "\n",
      "Wikipedia page token count: 633\n",
      "Question: Based on the previous description, please provide a short (1-3 words) gender of the composer\n",
      "Answer: Male\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class RequestError(Exception):\n",
    "    \"\"\"Custom exception for request handling errors.\"\"\"\n",
    "    def __init__(self, message, status_code=None):\n",
    "        super().__init__(message)\n",
    "        self.status_code = status_code\n",
    "\n",
    "def make_get_request(url, headers=None):\n",
    "    \"\"\"Perform a GET request.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()  # Raise HTTPError for bad requests\n",
    "        return response\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        raise RequestError(f\"HTTP Error: {response.status_code} - {response.text}\", status_code=response.status_code)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise RequestError(f\"Request Exception: {e}\")\n",
    "\n",
    "def make_post_request(url, data=None, json=None, headers=None):\n",
    "    \"\"\"Perform a POST request.\"\"\"\n",
    "    try:\n",
    "        response = requests.post(url, data=data, json=json, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return response\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        raise RequestError(f\"HTTP Error: {response.status_code} - {response.text}\", status_code=response.status_code)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise RequestError(f\"Request Exception: {e}\")\n",
    "\n",
    "def query_llm(text, endpoint=\"http://localhost:1234/v1/chat/completions\", max_tokens=400):\n",
    "    \"\"\"Send a query to the local LLM and return the response with a token limit.\"\"\"\n",
    "    data = {\"messages\": [{\"role\": \"user\", \"content\": text}], \"max_tokens\": max_tokens}\n",
    "    try:\n",
    "        response = make_post_request(endpoint, json=data)\n",
    "        return response.json().get('choices', [{}])[0].get('message', {}).get('content', \"No content returned.\").strip()\n",
    "    except (KeyError, IndexError, RequestError) as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "def get_wiki_content(url, token_limit=4096):\n",
    "    \"\"\"Fetch and parse content from a Wikipedia page, truncate if it exceeds token limit.\"\"\"\n",
    "    try:\n",
    "        response = make_get_request(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        content_text = ' '.join(p.get_text() for p in soup.find_all('p'))\n",
    "        tokens = content_text.split()\n",
    "        print(f\"Wikipedia page token count: {len(tokens)}\")  # Always output token count\n",
    "        if len(tokens) > token_limit:\n",
    "            # Truncate tokens to the token_limit\n",
    "            content_text = ' '.join(tokens[:token_limit])\n",
    "            print(f\"Content truncated to {token_limit} tokens.\")\n",
    "        return content_text\n",
    "    except RequestError as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "\n",
    "def summarize_wiki_article_with_limit(url, token_limit=4096, summary_word_limit=200):\n",
    "    \"\"\"Fetch, parse, and summarize a Wikipedia article using the local LLM, considering token limits.\"\"\"\n",
    "    try:\n",
    "        article_content = get_wiki_content(url, token_limit=token_limit)\n",
    "        if article_content.startswith(\"Error:\"):\n",
    "            return article_content\n",
    "        summary_prompt = f\"Summarize the following Wikipedia article content in about {summary_word_limit} words: {article_content}\"\n",
    "        summary = query_llm(summary_prompt)\n",
    "        if not summary.startswith(\"Error:\"):\n",
    "            # Truncate the summary to ensure it does not exceed the word limit\n",
    "            summary_words = summary.split()\n",
    "            if len(summary_words) > summary_word_limit:\n",
    "                summary = ' '.join(summary_words[:summary_word_limit])\n",
    "        return summary\n",
    "    except RequestError as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "def answer_question(question, url, token_limit=4096):\n",
    "    \"\"\"Get an answer to a question based on the Wikipedia article at the provided URL.\"\"\"\n",
    "    try:\n",
    "        context = get_wiki_content(url, token_limit=token_limit)\n",
    "        if context.startswith(\"Error:\"):\n",
    "            return context\n",
    "        question_prompt = f\"Given the context: {context}, answer the question: {question}\"\n",
    "        return query_llm(question_prompt)\n",
    "    except RequestError as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "wiki_url = \"https://en.wikipedia.org/wiki/Ivan_Dzerzhinsky\"\n",
    "\n",
    "# summary = summarize_wiki_article_with_limit(wiki_url, token_limit=8192, summary_word_limit=200)\n",
    "# print(\"Summary:\", summary)\n",
    "# print(\"\\n\")\n",
    "\n",
    "specific_question = \"Based on the text, provide a short cohesive description (100 words) of the countries the composer had affiliations with or citizenships in\"\n",
    "answer = answer_question(specific_question, wiki_url, token_limit=8192)\n",
    "print(\"Question:\", specific_question)\n",
    "print(\"Answer:\", answer)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "specific_question2 = \"Based on the previous description, please provide a short (1-3 words) nationality of the composer\"\n",
    "answer = answer_question(specific_question2, wiki_url, token_limit=8192)\n",
    "print(\"Question:\", specific_question2)\n",
    "print(\"Answer:\", answer)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "specific_question3 = \"Based on the previous description, please provide a short (1-3 words) gender of the composer\"\n",
    "answer = answer_question(specific_question3, wiki_url, token_limit=8192)\n",
    "print(\"Question:\", specific_question3)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0bc812-40dd-4e08-9408-06d77de15d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
